{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FLTvKyXe3Fy"
   },
   "source": [
    "# **Optimal Wifi-Hotspot Positioning Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3VdD5z2fD_D"
   },
   "source": [
    "This notebook performs analysis on architectural plans, particularly focusing on identifying zones, walls, and other features. It then applies graph theory to optimize the placement of WiFi hotspots.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal WiFi-Hotspot Positioning - QUBO/Ising ---- Repo is available here : https://github.com/samgr55/OptimalWiFi-HotspotPositioning_QUBO-Ising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zrN4TTNfbZg"
   },
   "source": [
    "# **Importing Libraries**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDmcqijPoFM2"
   },
   "source": [
    "The script starts by importing various libraries for image processing, machine learning, geometric operations, and more.                                    \n",
    "Some of the notable libraries used are:\n",
    "*   **cv2** (OpenCV for image processing)\n",
    "*   **skimage.metrics** (for structural similarity calculation)*italicized text*\n",
    "*   **matplotlib** (for visualization)\n",
    "*   **shapely** (for geometric operations)\n",
    "*   **dimod** (for solving optimization problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyS1HQtlcKqi"
   },
   "outputs": [],
   "source": [
    "from dimod import BinaryQuadraticModel, SimulatedAnnealingSampler, BINARY\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.affinity import scale, translate\n",
    "from shapely.geometry import LinearRing, LineString, MultiPoint, Point, MultiLineString, MultiPolygon\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from shapely.ops import unary_union\n",
    "#import dynex\n",
    "import dimod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOy0NPrmhkuZ"
   },
   "source": [
    "# **Architectural Plan Image Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HysHM0QwuwQc"
   },
   "source": [
    "***Determine if the input image is an architectural plan or not***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVXZOl5rkoVu"
   },
   "source": [
    "### **preprocessing test image**\n",
    "The function ***preprocess_test_img*** is defined to preprocess a new image. The function loads the reference architectural plan image, resizes the new image to match its dimensions, calculates the SSIM score, reshapes and scales the score using a trained scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7Ed20GjhGvU"
   },
   "outputs": [],
   "source": [
    "def preprocess_test_img(image_path, scaler):\n",
    "    reference_architectural_plan_path = \"Dataset/4.png\"\n",
    "    # reference_architectural_plan_path = \"datasets/FPOP-dataset/OWHP/4.png\"\n",
    "    reference_architectural_plan = cv2.imread(reference_architectural_plan_path)\n",
    "    new_image = cv2.imread(image_path)\n",
    "    new_image_resized = cv2.resize(new_image, (1167, 875))\n",
    "    similarity_score = ssim(new_image_resized, reference_architectural_plan, channel_axis=2)\n",
    "    similarity_score_reshaped = similarity_score.reshape(1, -1)\n",
    "    similarity_score_scaled = scaler.transform(similarity_score_reshaped)\n",
    "    return similarity_score_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrnhzqBAkXuz"
   },
   "source": [
    "### **Loading the pre-trained SVM model**\n",
    " The function ***load_architectural_plan_model*** load a saved Support Vector Machine (SVM) model for architectural plan classification using preprocessed similarity scores between images. The script involves preprocessing the input image to calculate a similarity score using Structural Similarity Index (SSIM), scaling the score using a previously trained scaler, and then making predictions using the loaded SVM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: NOT used in this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnbsJLqWjBCS"
   },
   "outputs": [],
   "source": [
    "def load_architectural_plan_model(new_image_path):\n",
    "    # Load the saved SVM model\n",
    "    loaded_model = joblib.load(\"svm_arch_plan_model.joblib\")\n",
    "    scaler = joblib.load(\"scaler.joblib\")\n",
    "\n",
    "    # Preprocess the new image if needed (resize, normalize, etc.)\n",
    "    similarity_score_scaled =preprocess_test_img(new_image_path,scaler)\n",
    "    # Predict using the loaded SVM model\n",
    "    prediction = loaded_model.predict(similarity_score_scaled)\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYTZhjz2niXo"
   },
   "source": [
    "# **IMG2GRAPH**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQdaoZA9u47l"
   },
   "source": [
    "***Convert the architectural plan image into a graph representation.***\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdIPQMByfx9j"
   },
   "source": [
    "### **Color Definitions and Tolerances**\n",
    "Define color palettes, mapping colors to categories, and tolerances for color matching. These are used to identify different zones or areas within the architectural plan based on color information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGx5MbhccKqj"
   },
   "outputs": [],
   "source": [
    "palette_colors = {\n",
    "    ( 229, 242,244): \"corridor\",\n",
    "    (135, 216, 208): \"Terrace\",\n",
    "    (214, 216,234 ): \"kitchen\",\n",
    "    (171, 244, 253): \"Bedroom\",\n",
    "    (252, 233,205 ): \"Bathroom\",\n",
    "    (189, 222, 249): \"store\",\n",
    "    (30, 225, 255): \"entrance\",\n",
    "    (79, 79, 79): \"exterior_wall\",\n",
    "    (128, 128, 128): \"interior_wall\"\n",
    "}\n",
    "tolerances = {\n",
    "     ( 229, 242,244): 0.01,\n",
    "     (135, 216, 208): 0.01,\n",
    "     (214, 216,234 ): 0.01,\n",
    "     (171, 244, 253): 0.01,\n",
    "     (252, 233,205 ): 0.01,\n",
    "     (189, 222, 249): 0.01,\n",
    "     (30, 225, 255): 0.1,\n",
    "     (79, 79, 79): 0.001,\n",
    "     (128, 128, 128): 0.001\n",
    "}\n",
    "category_colors = {\n",
    "    \"corridor\": (244, 242, 229),\n",
    "    \"Terrace\": (208, 216, 135),\n",
    "    \"kitchen\": (234, 216, 214),\n",
    "    \"Bedroom\": (253, 244, 171),\n",
    "    \"Bathroom\": (205, 233, 252),\n",
    "    \"store\": (249, 222, 189),\n",
    "    \"entrance\": (255, 225, 30),\n",
    "    \"exterior_wall\":(79, 79, 79),\n",
    "    \"interior_wall\": (128, 128, 128),\n",
    "    \"reinforcement_concrete_interior_wall\": (255, 0, 0),\n",
    "    \"opening\":(0,0,255)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sm-8NNC8gc6V"
   },
   "source": [
    "### **Categorizing Colors**\n",
    "The function **categorize_color** matches a given color to the nearest predefined color in the palette, helping to categorize different zones in the image based on their colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgRdq2YlcKqk"
   },
   "outputs": [],
   "source": [
    "def categorize_color(color):\n",
    "    nearest_color = min(palette_colors, key=lambda c: np.linalg.norm(np.array(c) - np.array(color)))\n",
    "    return palette_colors[nearest_color]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNNt6dm0g376"
   },
   "source": [
    "### **Edge Detection and Walls Baselines Extraction**\n",
    "Define functions to detect edges and extract lines from the architectural plan image. These lines could represent walls or other structures. The extracted lines are grouped using techniques like DBSCAN and cleaned up to remove short or overlapping lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qyx49pSsgza5"
   },
   "outputs": [],
   "source": [
    "def ext_line_wall(image, line_thickness=3):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh=cv2.threshold(gray,90,255,cv2.THRESH_BINARY_INV)\n",
    "    # cv2.imshow('Thresh', thresh)\n",
    "    edges = cv2.Canny(thresh, threshold1=30, threshold2=200)\n",
    "    kernel = np.ones((line_thickness, line_thickness), np.uint8)\n",
    "    dilated_edges = cv2.dilate(edges, kernel, iterations=0)\n",
    "    contours, _ = cv2.findContours(dilated_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    min_contour_area = line_thickness * 10  \n",
    "    filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_contour_area]\n",
    "\n",
    "    img = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2RGB)\n",
    "    result = img.copy()\n",
    "    return result,filtered_contours\n",
    "\n",
    "def extract_h_lines(dilated):\n",
    "    edges = cv2.Canny(dilated, threshold1=10, threshold2=255)\n",
    "    kernel= np.ones((5,5), np.uint8)\n",
    "    dilated_edges = cv2.dilate(edges, kernel, iterations=-3)\n",
    "    # Apply Hough Line Transform to detect vertical lines\n",
    "    lines = cv2.HoughLinesP(dilated_edges, 0.375, np.pi / 180, threshold=25, minLineLength=3, maxLineGap=17)\n",
    "    line_endpoints = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        line_endpoints.append((x1, y1, x2, y2))\n",
    "    # Apply DBSCAN to cluster similar lines\n",
    "    epsilon = 20 \n",
    "    min_samples = 2 \n",
    "    dbscan = DBSCAN(eps=epsilon, min_samples=min_samples).fit(line_endpoints)\n",
    "\n",
    "\n",
    "    clustered_lines = defaultdict(list)\n",
    "    for i, label in enumerate(dbscan.labels_):\n",
    "        clustered_lines[label].append(line_endpoints[i])\n",
    "    for cluster_id, lines_in_cluster in clustered_lines.items():\n",
    "        if cluster_id == -1:\n",
    "            continue  # Skip noise points\n",
    "        average_line = np.mean(lines_in_cluster, axis=0, dtype=int)\n",
    "        x1, y1, x2, y2 = average_line\n",
    "        # cv2.line(blank, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
    "    return (clustered_lines)\n",
    "\n",
    "def extract_v_lines(dilated):\n",
    "    edges = cv2.Canny(dilated, threshold1=5, threshold2=255)\n",
    "    kernel= np.ones((3,3), np.uint8)\n",
    "    dilated_edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "    lines = cv2.HoughLinesP(dilated_edges, 0.115899, np.pi / 180, threshold=11 ,minLineLength=3, maxLineGap=1)\n",
    "    line_endpoints = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        line_endpoints.append((x1, y1, x2, y2))\n",
    "    # Apply DBSCAN to cluster similar lines\n",
    "    epsilon = 20 \n",
    "    min_samples = 2  \n",
    "    dbscan = DBSCAN(eps=epsilon, min_samples=min_samples).fit(line_endpoints)\n",
    "    \n",
    "    clustered_lines = defaultdict(list)\n",
    "    for i, label in enumerate(dbscan.labels_):\n",
    "        clustered_lines[label].append(line_endpoints[i])\n",
    "    for cluster_id, lines_in_cluster in clustered_lines.items():\n",
    "        if cluster_id == -1:\n",
    "            continue  # Skip noise points\n",
    "        average_line = np.mean(lines_in_cluster, axis=0, dtype=int)\n",
    "        x1, y1, x2, y2 = average_line\n",
    "        # cv2.line(blank, (x1, y1), (x2, y2), (10,255, 20), 1)\n",
    "    return (clustered_lines)\n",
    "\n",
    "def remove_short_overlapping_lines(clustered_lines, min_overlap_distance=1, min_line_length=1):\n",
    "    new_clustered_lines = defaultdict(list)\n",
    "    for cluster_id, lines_in_cluster in clustered_lines.items():\n",
    "        if cluster_id == -1:\n",
    "            continue\n",
    "        new_lines_in_cluster = []\n",
    "        for line in lines_in_cluster:\n",
    "            x1, y1, x2, y2 = line\n",
    "            line_length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "            is_short = line_length < min_line_length\n",
    "            is_overlapping = any(np.abs(y1 - y2) < min_overlap_distance for _, _, y1, y2 in lines_in_cluster)\n",
    "            if not is_short and not is_overlapping:\n",
    "                average_line = np.mean(lines_in_cluster, axis=0, dtype=int)\n",
    "                new_lines_in_cluster.append(average_line)\n",
    "        if new_lines_in_cluster:\n",
    "            new_clustered_lines[cluster_id] = new_lines_in_cluster\n",
    "    return new_clustered_lines\n",
    "\n",
    "def remove_close_lines(clustered_lines, max_distance=15, max_length_difference=25):\n",
    "    new_clustered_lines = defaultdict(list)\n",
    "\n",
    "    def calculate_distance(line1, line2):\n",
    "        x1, y1, x2, y2 = line1\n",
    "        nx1, ny1, nx2, ny2 = line2\n",
    "        return np.sqrt((x1 - nx1)**2 + (y1 - ny1)**2)\n",
    "\n",
    "    for cluster_id, lines_in_cluster in clustered_lines.items():\n",
    "        if cluster_id == -1:\n",
    "            continue\n",
    "        merged_lines = []\n",
    "        used_indices = set()\n",
    "        for i, current_line in enumerate(lines_in_cluster):\n",
    "            if i in used_indices:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = current_line\n",
    "            close_lines = [current_line]\n",
    "            used_indices.add(i)\n",
    "            for j, next_line in enumerate(lines_in_cluster[i+1:], start=i+1):\n",
    "                if j in used_indices:\n",
    "                    continue\n",
    "                nx1, ny1, nx2, ny2 = next_line\n",
    "                if calculate_distance(current_line, next_line) < max_distance:\n",
    "                    if abs(y1 - ny1) < max_length_difference or abs(y2 - ny2) < max_length_difference:\n",
    "                        close_lines.append(next_line)\n",
    "                        used_indices.add(j)\n",
    "            merged_points = np.mean(close_lines, axis=0, dtype=int)\n",
    "            merged_line = (merged_points[0], merged_points[1], merged_points[2], merged_points[3])\n",
    "            merged_lines.append(merged_line)\n",
    "        new_clustered_lines[cluster_id] = merged_lines\n",
    "    return new_clustered_lines\n",
    "\n",
    "def int_line_walls(image, line_thickness=3):\n",
    "    img = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2RGB)\n",
    "    cnt_img =cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
    "    walls=cnt_img\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh=cv2.threshold(gray,10,255,cv2.THRESH_BINARY_INV)\n",
    "    # cv2.imshow('thresh',thresh)\n",
    "    kernel_H = np.ones((1,5), np.uint8)\n",
    "    dilated_edges_h = cv2.dilate(thresh, kernel_H, iterations=3)\n",
    "    # cv2.imshow('h',dilated_edges_h)\n",
    "    kernel_V = np.ones((7, 1), np.uint8)\n",
    "    dilated_edges_v = cv2.dilate(thresh, kernel_V, iterations=-3)\n",
    "    # cv2.imshow('v',dilated_edges_v)\n",
    "    h_lines = extract_h_lines(dilated_edges_h)\n",
    "    v_lines = extract_v_lines(dilated_edges_v)\n",
    "    h_lines = remove_short_overlapping_lines(h_lines)\n",
    "    v_lines = remove_short_overlapping_lines(v_lines)\n",
    "    h_lines = remove_close_lines(h_lines)\n",
    "    v_lines = remove_close_lines(v_lines)\n",
    "    merged_lines = defaultdict(list)\n",
    "    for cluster_id, lines in h_lines.items():\n",
    "        merged_lines[cluster_id].extend(lines)\n",
    "    for cluster_id, lines in v_lines.items():\n",
    "        merged_lines[cluster_id].extend(lines)\n",
    "    flattened_lines = []\n",
    "    for lines_in_cluster in merged_lines.values():\n",
    "        for line in lines_in_cluster:\n",
    "            flattened_lines.append(line)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return walls,flattened_lines\n",
    "def preprocess_mask(mask):\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    return opening\n",
    "\n",
    "def draw_lines(mask,imgLines,EXT):\n",
    "    if EXT==True:\n",
    "            # line_image,lines=ext_line_walls(imgLines.copy(),line_thickness=3)\n",
    "            line_image,lines=ext_line_wall(imgLines.copy(),line_thickness=3)\n",
    "    else:\n",
    "       if EXT==False:\n",
    "            line_image,lines=int_line_walls(mask.copy(),line_thickness=3)\n",
    "    return line_image,lines\n",
    "def are_boundaries_adjacent(boundary1, boundary2, distance_threshold=30):\n",
    "    min_edge_distance = np.min([np.min([np.linalg.norm(pt1 - pt2) for pt1 in boundary1 for pt2 in boundary2_edge]) for boundary2_edge in [boundary2, np.flip(boundary2, axis=0)]])\n",
    "    return min_edge_distance < distance_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_JbaknNqXwi"
   },
   "source": [
    "### **Graph Creation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCrj_LxCqiiL"
   },
   "source": [
    "The function ***convert_image_to_graph*** processes the image and creates a graph representation of the architectural plan. Nodes in the graph represent different zones or areas, and edges are added based on adjacency of boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2rrFyIDroYQ"
   },
   "source": [
    "**Node Creation**\n",
    "\n",
    "> Each categorized zone from the image corresponds to a node in the graph. Nodes are created based on the color categories identified earlier. These nodes represent different areas in the architectural plan, such as rooms, corridors, and open spaces.\n",
    "\n",
    "**Boundary-based Edge Creation**\n",
    "\n",
    "\n",
    "> Edges are created between nodes based on the adjacency of their boundaries. If two zones share a boundary in the architectural plan, an edge is added between the corresponding nodes in the graph. This step establishes the spatial relationships between different areas in the plan.\n",
    "\n",
    " **Graph Modification**\n",
    "\n",
    ">  Including a section for modifying the graph. Select nodes representing interior walls and changes their category to \"reinforcement_concrete_interior_wall\" to simulate reinforced walls.\n",
    "\n",
    " **Graph Representation**\n",
    "\n",
    "\n",
    "> The final result of this process is a graph where nodes represent different categorized zones, and edges represent the adjacency of boundaries between these zones. This graph can be thought of as a visual abstraction of the architectural plan, where areas and their connections are captured in a structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ewAjHVnKobGb"
   },
   "outputs": [],
   "source": [
    "def convert_image_to_graph(image_path):\n",
    "    zones = []\n",
    "    contours =[]\n",
    "    for color, category in palette_colors.items():\n",
    "        if category not in [\"exterior_wall\", \"interior_wall\"]:\n",
    "            tolerance = tolerances[color]\n",
    "            lower_bound = np.array(color) - np.array([tolerance * 255, tolerance * 255, tolerance * 255])\n",
    "            upper_bound = np.array(color) + np.array([tolerance * 255, tolerance * 255, tolerance * 255])\n",
    "            mask = cv2.inRange(cnt_img.copy(), lower_bound, upper_bound)\n",
    "            outlines, _ = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            count = 0\n",
    "            for contour in outlines:\n",
    "                area = cv2.contourArea(contour)\n",
    "                if area > 30:  # Filter out small noise regions\n",
    "                    moments = cv2.moments(contour)\n",
    "                    count += 1\n",
    "                    if moments[\"m00\"] != 0:\n",
    "                        cx = int(moments[\"m10\"] / moments[\"m00\"])\n",
    "                        cy = int(moments[\"m01\"] / moments[\"m00\"])\n",
    "                        zones.append({\n",
    "                            'category': f\"{category} {count}\" if count > 1 else category,\n",
    "                            'area': area,\n",
    "                            'centroid': (cx, cy),\n",
    "                            'boundary': contour\n",
    "                        })\n",
    "                    cv2.drawContours(cnt_img, [contour], -1, (0, 255, 0), 1)\n",
    "                    contours.append(contour)\n",
    "        else:\n",
    "            if category in [\"exterior_wall\", \"interior_wall\"]:\n",
    "                tolerance = tolerances[color]\n",
    "                lower_bound = np.array(color) - np.array([tolerance * 255, tolerance * 255, tolerance * 255])\n",
    "                upper_bound = np.array(color) + np.array([tolerance * 255, tolerance * 255, tolerance * 255])\n",
    "                mask = cv2.inRange(cnt_img.copy(), lower_bound, upper_bound)\n",
    "                masks = {label: np.zeros_like(image)[:, :, 0] for label in palette_colors.values()}\n",
    "                masks[category] += mask\n",
    "                result = cv2.bitwise_and(cnt_img, cnt_img, mask=mask[:, :, np.newaxis])\n",
    "                # accumulated_mask += mask\n",
    "                if category in {\"exterior_wall\"}:\n",
    "                    result = cv2.bitwise_and(cnt_img, cnt_img, mask=mask[:, :, np.newaxis])\n",
    "                    filtered_mask = preprocess_mask(result)\n",
    "                    # cv2.imshow(f\"{category} mask\",mask)\n",
    "                    line_mask,ext_lines = draw_lines(filtered_mask,cnt_img.copy(),True)\n",
    "                    count = 0\n",
    "                    for contour in ext_lines:\n",
    "                        area = cv2.contourArea(contour)\n",
    "                        if area > 30: \n",
    "                            moments = cv2.moments(contour)\n",
    "                            count += 1\n",
    "                            if moments[\"m00\"] != 0:\n",
    "                                cx = int(moments[\"m10\"] / moments[\"m00\"])\n",
    "                                cy = int(moments[\"m01\"] / moments[\"m00\"])\n",
    "                                zones.append({\n",
    "                                    'category': f\"{category} {count}\" if count > 1 else category,\n",
    "                                    'area': area,\n",
    "                                    'centroid': (cx, cy),\n",
    "                                    'boundary': contour\n",
    "                                })\n",
    "                            cv2.drawContours(cnt_img, [contour], -1, (255, 0, 0), 1)\n",
    "                            contours.append(contour)\n",
    "                else:\n",
    "                    if category == 'interior_wall':\n",
    "                        filtered_mask = preprocess_mask(result)\n",
    "                        line_mask, int_lines = draw_lines(filtered_mask, cnt_img.copy(),False)\n",
    "                        # cv2.imshow(f\"{category} lines\", line_mask)\n",
    "                        # print(len(int_lines))\n",
    "                        count = 0\n",
    "                        for line in int_lines:\n",
    "                            x1,y1,x2,y2=line\n",
    "                            line_length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "                            area = line_length*2\n",
    "                            # print(area)\n",
    "                            if area > 30: \n",
    "                                count += 1\n",
    "                                centroid_x = (x1 + x2) / 2\n",
    "                                centroid_y = (y1 + y2) / 2\n",
    "                                zones.append({\n",
    "                                    'category': f\"{category} {count}\" if count > 1 else category,\n",
    "                                    'area': area,\n",
    "                                    'centroid': (centroid_x, centroid_y),\n",
    "                                    'boundary': line\n",
    "                                })\n",
    "                                cv2.line(cnt_img, (x1, y1), (x2, y2), (100, 10, 200),thickness= 2,lineType=cv2.LINE_AA)\n",
    "                                contours.append(line)\n",
    "    # Create a graph\n",
    "    graph = nx.Graph()\n",
    "    interior_wall_nodes = []\n",
    "    terrace_nodes=[]\n",
    "    for zone in zones:\n",
    "        centroid = zone['centroid']\n",
    "        category = zone['category']\n",
    "        area = zone['area']\n",
    "        boundary = zone['boundary']\n",
    "        node_color = tuple(val / 255.0 for val in category_colors[category.split()[0]])\n",
    "        graph.add_node(centroid, category=category, area=area, boundary=boundary, color=node_color,centroid=centroid)\n",
    "\n",
    "        if category.startswith('interior_wall'):\n",
    "            # print(\"done\")\n",
    "            interior_wall_nodes = [\n",
    "                node for node, data in graph.nodes(data=True)\n",
    "                if data.get('category', '').startswith('interior_wall')\n",
    "            ]\n",
    "            # print(interior_wall_nodes)\n",
    "            if interior_wall_nodes:\n",
    "                largest_area_node = max(interior_wall_nodes, key=lambda node: graph.nodes[node].get('area', 0))\n",
    "                interior_wall_nodes.remove(largest_area_node)\n",
    "    terrace_node = [\n",
    "        node for node, data in graph.nodes(data=True)\n",
    "        if data.get('category', '').startswith('Terrace')\n",
    "    ]\n",
    "    terrace_nodes.extend(terrace_node)\n",
    "    for terrace in terrace_nodes:\n",
    "        terrace_position = terrace\n",
    "        for interior_wall_node in interior_wall_nodes:\n",
    "            interior_wall_position = np.array(graph.nodes[interior_wall_node]['centroid'])\n",
    "            distance = math.sqrt((terrace_position[0] - interior_wall_position[0])**2 + (terrace_position[1] - interior_wall_position[1])**2)\n",
    "            if distance <= 100:  # Adjust the distance threshold as needed\n",
    "                interior_wall_nodes.remove(interior_wall_node)\n",
    "                # print(\"done2\")\n",
    "    nodes_to_modify = interior_wall_nodes  # This assumes that interior_wall_nodes contains the modified node IDs\n",
    "    # Calculate the number of nodes to select for modification (80% of the total)\n",
    "    num_nodes_to_modify = int(len(nodes_to_modify) * 0.2)\n",
    "    selected_indices = np.random.choice(len(nodes_to_modify), size=num_nodes_to_modify, replace=True)\n",
    "    # Get the corresponding node IDs for modification\n",
    "    selected_nodes = [nodes_to_modify[i] for i in selected_indices]\n",
    "    for node in selected_nodes:\n",
    "        graph.nodes[node]['category'] = 'reinforcement_concrete_interior_wall'\n",
    "        graph.nodes[node]['color'] = (1.0, 0.0, 0.0)  # Red color\n",
    "    for zone in zones:\n",
    "        centroid = zone['centroid']\n",
    "        category = zone['category']\n",
    "        area = zone['area']\n",
    "        boundary = zone['boundary']\n",
    "        if category == 'entrance':\n",
    "            entrance_node =next(node for node, data in graph.nodes(data=True)if data.get('category').startswith('entrance'))\n",
    "            corridor_nodes = [node for node, data in graph.nodes(data=True) if data.get('category').startswith('corridor')]\n",
    "            closest_corridor_node = min(corridor_nodes, key=lambda corridor_node: np.linalg.norm(np.array(graph.nodes[entrance_node].get('centroid', (0, 0))) - np.array(graph.nodes[corridor_node].get('centroid', (0, 0)))))\n",
    "            ext_wall_node = next(node for node, data in graph.nodes(data=True) if data.get('category').startswith('exterior_wall'))\n",
    "            graph.add_edge(entrance_node, closest_corridor_node)\n",
    "            graph.add_edge(entrance_node, ext_wall_node)\n",
    "            entrance_boundary = graph.nodes[entrance_node]['boundary']\n",
    "            exterior_boundary = graph.nodes[ext_wall_node]['boundary']\n",
    "            entrance_polygon = Polygon([(pt[0][0], pt[0][1]) for pt in entrance_boundary])\n",
    "            given_entrance_polygon = LinearRing(entrance_polygon.exterior.coords)\n",
    "            exterior_polygon = Polygon([(pt[0][0], pt[0][1]) for pt in exterior_boundary])\n",
    "            given_exterior_polygon = LinearRing(exterior_polygon.exterior.coords)\n",
    "            offset_distance = 1.4  \n",
    "            offset_entrance_boundary = scale(given_entrance_polygon, xfact=  offset_distance, yfact= offset_distance)\n",
    "            offset_exterior_boundary = scale(given_exterior_polygon, xfact=  offset_distance, yfact=  offset_distance)\n",
    "            ent_centroid= given_entrance_polygon.centroid\n",
    "            nodes_to_add = []\n",
    "            scaled_boundaries = []\n",
    "            all_boundary_coords = []\n",
    "            exterior_coords = []\n",
    "            count=1\n",
    "            for i, (node1, data1) in enumerate(graph.nodes(data=True)):\n",
    "                category1 = data1['category']\n",
    "                # category2 = data1['category'].startswith('entrance', 'interior_wall', 'exterior_wall')\n",
    "                if category1 != 'entrance' and 'wall' not in category1:\n",
    "                    for j, (node2, data2) in enumerate(graph.nodes(data=True)):\n",
    "                        category2 = data2['category']\n",
    "                        if i != j and category2 != 'entrance' and 'wall' not in category2:\n",
    "                            boundary1 = data1['boundary']\n",
    "                            boundary2 = data2['boundary']\n",
    "                            boundary1_list = [(pt[0][0], pt[0][1]) for pt in boundary1]\n",
    "                            boundary2_list = [(pt[0][0], pt[0][1]) for pt in boundary2]\n",
    "                            linear_ring1 = LinearRing(boundary1_list)\n",
    "                            linear_ring2 = LinearRing(boundary2_list)\n",
    "                            offset_distance = 17\n",
    "                            offset_linear_ring1 = scale(linear_ring1, xfact=1 + offset_distance/100, yfact=1 + offset_distance/100)\n",
    "                            offset_linear_ring2 = scale(linear_ring2, xfact=1 + offset_distance/100, yfact=1 + offset_distance/100)\n",
    "                            intersectin=offset_linear_ring1.intersects(offset_linear_ring2)\n",
    "                            if intersectin or offset_linear_ring1.contains_properly(offset_linear_ring2):\n",
    "                                graph.add_edge(node1, node2,type='direct connection',weight=0.5)\n",
    "                    offset = -0.0001\n",
    "                    zone_boundary= data1['boundary']\n",
    "                    # print(zone_boundary)\n",
    "                    boundary_polygon = Polygon([(pt[0][0], pt[0][1]) for pt in zone_boundary])\n",
    "                    given_entrance_polygon = LinearRing(boundary_polygon.exterior.coords)\n",
    "                    scaled_boundary = given_entrance_polygon.offset_curve(offset,join_style='mitre',mitre_limit=0.01)\n",
    "                    scaled_boundaries.append(scaled_boundary)\n",
    "            merged_boundary = unary_union(scaled_boundaries)\n",
    "            if isinstance(merged_boundary, MultiLineString):\n",
    "                merged_polygon = merged_boundary.buffer(9,cap_style='flat',join_style='mitre',mitre_limit=0.05)\n",
    "            else:\n",
    "                merged_polygon = Polygon(merged_boundary)\n",
    "            graph.nodes[ext_wall_node]['boundary'] = merged_polygon.exterior\n",
    "            given_entrance_polygon=merged_polygon.exterior\n",
    "            if ext_wall_node is not None:\n",
    "                ext_wall_boundary = graph.nodes[ext_wall_node]['boundary']\n",
    "                for i in range(len(ext_wall_boundary.coords) - 1):\n",
    "                    start_point = ext_wall_boundary.coords[i]\n",
    "                    end_point = ext_wall_boundary.coords[i + 1]\n",
    "                    segment_length = np.linalg.norm(np.array(start_point) - np.array(end_point))\n",
    "                    if segment_length > 40:\n",
    "                        center_point = ((start_point[0] + end_point[0]) / 2, (start_point[1] + end_point[1]) / 2)\n",
    "                        # opening_node = len(graph.nodes)\n",
    "                        graph.add_node(center_point, category=f\"opening {count}\",boundary=[center_point],area=7*200,centroid=center_point)\n",
    "                        count+=1\n",
    "                offset_exterior_boundary = ext_wall_boundary.offset_curve(20,join_style='mitre',mitre_limit=1)\n",
    "                projected_distance =    offset_exterior_boundary.project(ent_centroid)\n",
    "                projected_point = offset_exterior_boundary.interpolate(projected_distance)\n",
    "                projected_point = projected_point.centroid\n",
    "            graph.nodes[ext_wall_node]['centroid'] = (projected_point.x,projected_point.y)\n",
    "    opening_nodes= [node for node, data in graph.nodes(data=True) if data.get('category').startswith('opening')]\n",
    "    for node in opening_nodes:\n",
    "        graph.add_edge(node, ext_wall_node,type='fixed connection',weight=1)\n",
    "            # print(graph.nodes)\n",
    "    return graph,opening_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcGhW0rLuF8l"
   },
   "source": [
    "# **Finding Best WiFi Spot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5KXOgTEvKiJ"
   },
   "source": [
    "***Optimize the placement of WiFi hotspots using graph theory and simulated annealing.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTsEnecgvMpi"
   },
   "source": [
    "\n",
    "using a simulated annealing solver from the ***dimod*** library to optimize the placement of WiFi hotspots in the graph. The goal is to find the best location for WiFi hotspots that satisfies certain constraints and objectives.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcVfoz2qzVNL"
   },
   "source": [
    "### **Defining zone categories, constrains and factors**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxCnWeYO0Tyf"
   },
   "source": [
    "> **Wi-Fi Spot Suitability**: place the Wi-Fi spot in a zone that is suitable. This suitability can be represented by a constraint value assigned to each zone.\n",
    "\n",
    "> **Proximity to Openings**: prefer the Wi-Fi spot to be close to opening like windows and terraces. calculate a value representing the proximity of a zone to opening.\n",
    "\n",
    "> **Avoiding Interior Walls**: avoid placing the Wi-Fi spot near concrete interior walls. assign a penalty value to zones that are close to such walls.\n",
    "\n",
    "> **Exclusion of Zones**: Certain zones like bathrooms, kitchens, and terraces should be excluded. assign a very high penalty value to these zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NwFpponOcKqj"
   },
   "outputs": [],
   "source": [
    "# Define your zone categories\n",
    "zone_categories = {\n",
    "    \"corridor\",\"Terrace\", \"opening\", \"kitchen\", \"Bedroom\", \"Bathroom\", \"store\",\n",
    "    \"entrance\", \"exterior_wall\", \"interior_wall\", \"reinforcement_concrete_interior_wall\"\n",
    "}\n",
    "suitability = {\n",
    "    \"corridor\": 0.8,\n",
    "    \"Terrace\": 0.0, \n",
    "    \"opening\": 0.9,\n",
    "    \"kitchen\": 0.0,  \n",
    "    \"Bedroom\": 0.6,\n",
    "    \"Bathroom\": 0.0,  \n",
    "    \"store\": 0.3,\n",
    "    \"entrance\": 0.8,\n",
    "    \"exterior_wall\": 0.0,  \n",
    "    \"interior_wall\": 0.0,  \n",
    "    \"reinforcement_concrete_interior_wall\": 0.0\n",
    "}\n",
    "proximity = {\n",
    "    \"corridor\": 0.7,\n",
    "    \"Terrace\": 0.6,\n",
    "    \"opening\": 5.0,\n",
    "    \"kitchen\": 0.0,\n",
    "    \"Bedroom\": 0.5,\n",
    "    \"Bathroom\": 0.1,\n",
    "    \"store\": 0.4,\n",
    "    \"entrance\": 0.7,\n",
    "    \"exterior_wall\": 0.5,  \n",
    "    \"interior_wall\": 0.0,  \n",
    "    \"reinforcement_concrete_interior_wall\": 0.0\n",
    "}\n",
    "wall_penalty = {\n",
    "    \"corridor\": 0.1,\n",
    "    \"Terrace\": 0.6,\n",
    "    \"opening\": 0.2,\n",
    "    \"kitchen\": 0.3,\n",
    "    \"Bedroom\": 0.1,\n",
    "    \"Bathroom\": 0.8,\n",
    "    \"store\": 0.4,\n",
    "    \"entrance\": 0.2,\n",
    "    \"exterior_wall\": 1.0,\n",
    "    \"interior_wall\":1.0,\n",
    "    \"reinforcement_concrete_interior_wall\": 100\n",
    "}\n",
    "exclusion_penalty = {\n",
    "    \"corridor\": 0.0,\n",
    "    \"Terrace\": 0.0, \n",
    "    \"opening\": 0.0,\n",
    "    \"kitchen\": 1.0,  \n",
    "    \"Bedroom\": 0.0,\n",
    "    \"Bathroom\": 1.0,  \n",
    "    \"store\": 1.0,\n",
    "    \"entrance\": 0.0,\n",
    "    \"exterior_wall\": 1.0,  \n",
    "    \"interior_wall\": 1.0,  \n",
    "    \"reinforcement_concrete_interior_wall\": 100\n",
    "}\n",
    "category_to_value = {\n",
    "    \"corridor\": 1,\n",
    "    \"Terrace\": 2,\n",
    "    \"kitchen\": 3,\n",
    "    \"Bedroom\": 4,\n",
    "    \"Bathroom\": 5,\n",
    "    \"store\": 6,\n",
    "    \"entrance\": 7,\n",
    "    \"exterior_wall\": 8,\n",
    "    \"interior_wall\": 9,\n",
    "    \"reinforcement_concrete_interior_wall\": 10,\n",
    "    \"opening\": 11\n",
    "}\n",
    "constraints = {}\n",
    "for zone_category in suitability.keys():\n",
    "    constraints[('suitability', zone_category)] = suitability[zone_category]\n",
    "    constraints[('proximity', zone_category)] = proximity[zone_category]\n",
    "    constraints[('wall_penalty', zone_category)] = wall_penalty[zone_category]\n",
    "    constraints[('exclusion_penalty', zone_category)] = exclusion_penalty[zone_category]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW1913OP52hJ"
   },
   "source": [
    "### **Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAgX1PB95pSj"
   },
   "source": [
    "The function ***find_best_wifi_spot*** performs simulated annealing optimization using the Dynex Annealing Sampler for finding the best location to place a WiFi hotspot on the floor plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsEC0s05cKqn"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def find_best_wifi_spot(bqm, graph):\n",
    "    exterior_wall_node = [node for node, data in graph.nodes(data=True) if data['category'] == 'exterior_wall'][0]\n",
    "    initial_x_coord = graph.nodes[exterior_wall_node]['centroid'][0]\n",
    "    initial_y_coord = graph.nodes[exterior_wall_node]['centroid'][1]\n",
    "\n",
    "    # Solve the BQM using a DynexBQM sampler (simulated annealing)\n",
    "    \n",
    "    sampler = SimulatedAnnealingSampler()\n",
    "    response = sampler.sample(bqm, num_reads=1000)\n",
    "    best_sample = response.first.sample\n",
    "    print('SA RESULT:',best_sample);\n",
    "    \n",
    "    \n",
    "    '''    \n",
    "    # Solve with Dynex Platform\n",
    "    model = dynex.BQM(bqm);\n",
    "    sampler = dynex.DynexSampler(model,  mainnet=True, description='SamRahmeh-OptimalWiFi-HotspotPositioning')\n",
    "    sampleset = sampler.sample(num_reads=10000, annealing_time = 1000, debugging=True);\n",
    "    '''\n",
    "    \n",
    "    # optional, less optimal reads (but feasible) can also be chosen:\n",
    "    '''\n",
    "    energy = 1e9;\n",
    "    best_sample = [];\n",
    "    for sample in sampleset:\n",
    "        if max([float(i) for i in sample['sample']])>0.0 and sample['energy'] < energy and sample['energy']>0:\n",
    "            energy = sample['energy'];\n",
    "            best_sample = sample['sample'];\n",
    "            print('DEBUG: best sample taken with energy',sample['energy']);\n",
    "    \n",
    "    sample = {};\n",
    "    i = 0;\n",
    "    for var in sampler.var_mappings:\n",
    "        sample[var] = 1;\n",
    "        if (float(best_sample[i])<0):\n",
    "            sample[var] = 0;\n",
    "        i = i + 1\n",
    "    \n",
    "    best_sample = dimod.SampleSet.from_samples_bqm(sample, bqm).first.sample;\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    best_sample = sampler.dimod_assignments.first.sample;\n",
    "    print('DYNEX RESULT:',best_sample)\n",
    "    '''\n",
    "    best_x_coord = {node: best_sample['x_coord_{}'.format(node)] for node in graph.nodes()}\n",
    "    best_y_coord = {node: best_sample['y_coord_{}'.format(node)] for node in graph.nodes()}\n",
    "    dist_x = {node: initial_x_coord - best_x_coord[node] for node in graph.nodes()}\n",
    "    dist_y = {node: initial_y_coord - best_y_coord[node] for node in graph.nodes()}\n",
    "\n",
    "    max_distance_threshold = 15 \n",
    "    penalty_x = {node: abs(dist) if abs(dist) > max_distance_threshold else 0 for node, dist in dist_x.items()}\n",
    "    penalty_y = {node: abs(dist) if abs(dist) > max_distance_threshold else 0 for node, dist in dist_y.items()}\n",
    "    for node, penalty in penalty_x.items():\n",
    "        bqm.add_linear('x_coord_{}'.format(node), penalty)\n",
    "    for node, penalty in penalty_y.items():\n",
    "        bqm.add_linear('y_coord_{}'.format(node), penalty)\n",
    "    sum_x = 0\n",
    "    sum_y = 0\n",
    "    count = 0\n",
    "    for node, value in best_sample.items():\n",
    "        if value == 1 and 'x_coord_' in node:\n",
    "            category = node.split('_')[1]\n",
    "            if category not in {\"kitchen\", \"Bathroom\", \"reinforcement_concrete_interior_wall\"}:\n",
    "                coords = node.split('_')[2].strip(\"()\")\n",
    "                x_coord, y_coord = map(float, coords.split(','))\n",
    "                sum_x += x_coord\n",
    "                sum_y += y_coord\n",
    "                count += 1\n",
    "    if count == 0:\n",
    "        count = 1;\n",
    "    average_x = sum_x / count\n",
    "    average_y = sum_y / count\n",
    "    x_coords = average_x\n",
    "    y_coords = average_y\n",
    "    return best_sample, x_coords, y_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q36ik_1S5PLG"
   },
   "source": [
    "### **Wifi_hotspot Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yu2HLlKb5PcV"
   },
   "outputs": [],
   "source": [
    "def visualize_arch_plan_with_wifi(image_path):\n",
    "    graph, opening_nodes = convert_image_to_graph(image_path)\n",
    "    # Initialize BQM\n",
    "    bqm = BinaryQuadraticModel.empty(vartype=BINARY)\n",
    "    for node in graph.nodes():\n",
    "        bqm.add_variable('x_coord_{}'.format(node), 0.0)\n",
    "        bqm.add_variable('y_coord_{}'.format(node), 0.0)\n",
    "    print(bqm.variables)\n",
    "    exterior_wall_centroid = None\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        if data['category'] == 'exterior_wall':\n",
    "            exterior_wall_node = node\n",
    "            exterior_wall_centroid = data['centroid']\n",
    "            initial_x_coord = data['centroid'][0]\n",
    "            initial_y_coord = data['centroid'][1]\n",
    "            break\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        category = ''.join(filter(lambda x: not x.isdigit(), data['category'])).strip()\n",
    "        linear_coefficient = category_to_value.get(category.startswith(zone_category), 0.0)\n",
    "        bqm.add_linear(node, linear_coefficient)\n",
    "        category_name_without_numbers = ''.join([c for c in data['category'] if not c.isdigit()])\n",
    "        category_key = next((key for key in suitability.keys() if category_name_without_numbers in key), None)\n",
    "        if category_key is not None:\n",
    "            linear_coefficient = suitability[category_key]\n",
    "            dist_x = initial_x_coord - data['centroid'][0]\n",
    "            dist_y = initial_y_coord - data['centroid'][1]\n",
    "            coeff_x = (\n",
    "                linear_coefficient +\n",
    "                proximity[category_key] -\n",
    "                wall_penalty[category_key] -\n",
    "                exclusion_penalty[category_key] -\n",
    "                dist_x\n",
    "            )\n",
    "            coeff_y = (\n",
    "                linear_coefficient +\n",
    "                proximity[category_key] -\n",
    "                wall_penalty[category_key] -\n",
    "                exclusion_penalty[category_key] -\n",
    "                dist_y\n",
    "            )\n",
    "            bqm.add_linear(node, coeff_x); \n",
    "            bqm.add_linear(node, coeff_y);\n",
    "\n",
    "        else:\n",
    "            linear_coefficient = 0.0\n",
    "            dist_x = 0.0\n",
    "            dist_y = 0.0\n",
    "    \n",
    "    # sampling:\n",
    "    best_node,best_x_coord, best_y_coord= find_best_wifi_spot(bqm, graph)\n",
    "    \n",
    "    node_labels = {node: data['category'] for node, data in graph.nodes(data=True)}\n",
    "    node_sizes = [data['area'] * 0.01 for node, data in graph.nodes(data=True)]\n",
    "    node_colors = [tuple(val / 255.0 for val in category_colors[data['category'].split()[0]]) for node, data in graph.nodes(data=True)]\n",
    "    pos = {node: data['centroid'] for node, data in graph.nodes(data=True)} # Use the centroid as the node position\n",
    "\n",
    "\n",
    "    # Visualize the graph\n",
    "    plt.figure(figsize=(10,10))\n",
    "    # nx.draw(graph, pos, node_size=node_sizes, node_color=node_colors, labels=node_labels, font_size=5)\n",
    "    nodes=graph.nodes()\n",
    "    subgraph_nodes = [node for node, data in graph.nodes(data=True) if node not in opening_nodes]\n",
    "    subgraph = graph.subgraph(subgraph_nodes)\n",
    "    pos_subgraph = {node: data['centroid'] for node, data in subgraph.nodes(data=True) if node in subgraph_nodes}\n",
    "    nx.draw_networkx_nodes(subgraph, pos, nodelist=nodes, node_size=node_sizes, node_color=node_colors,node_shape='o',edgecolors='black')\n",
    "    nx.draw_networkx_labels(subgraph, pos, labels=node_labels, font_size=4, font_color='black',verticalalignment='bottom')\n",
    "    edges_to_draw = subgraph.edges()\n",
    "    nx.draw_networkx_edges(graph, pos_subgraph, edgelist=edges_to_draw,style='dashed',alpha=0.6)\n",
    "    best_node_str = \",\".join([f\"{key}:{value}\" for key, value in best_node.items()])\n",
    "    graph.add_node(best_node_str, category=\"best_wifi_spot\")\n",
    "    plt.scatter(best_x_coord, best_y_coord, s=100, c='green', marker='o', edgecolors='black')\n",
    "    plt.axis('auto')\n",
    "\n",
    "    plt.imshow(cnt_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4mWcQHj7OnU"
   },
   "source": [
    "# **Analysis Workflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the GREEN_DOT is the optimal position for the WiFi-Hotspot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S524nI9_cKqo"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "images_folder = \"dataset/\"\n",
    "# images_folder = \"datasets/FPOP-dataset/OWHP\"\n",
    "# Iterate through each plan for computing\n",
    "for filename in os.listdir(images_folder):\n",
    "    if filename.endswith((\".png\", \".jpg\")):\n",
    "        image_path = os.path.join(images_folder, filename)\n",
    "        image=cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2RGB)\n",
    "        cnt_img =cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
    "        visualize_arch_plan_with_wifi(image_path)\n",
    "        #input(\"Press Enter to continue...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
